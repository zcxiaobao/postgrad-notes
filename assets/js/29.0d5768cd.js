(window.webpackJsonp=window.webpackJsonp||[]).push([[29],{408:function(v,_,t){"use strict";t.r(_);var s=t(51),e=Object(s.a)({},(function(){var v=this,_=v.$createElement,t=v._self._c||_;return t("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[t("h2",{attrs:{id:"工作进度"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#工作进度"}},[v._v("#")]),v._v(" 工作进度")]),v._v(" "),t("h3",{attrs:{id:"识别准确率的提高"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#识别准确率的提高"}},[v._v("#")]),v._v(" 识别准确率的提高")]),v._v(" "),t("p",[v._v("修复完 model 未重置问题后，PLAID2017 和 WHITED1.1 的准确率分别在 96.2 和 96.5 左右(传入的通道图边长为 50)，这两周做了很多微调，尝试提高识别的准确率。")]),v._v(" "),t("p",[v._v("首先尝试了一些超参数的微调，分别对 batchsize 和学习率 lr 进行调整")]),v._v(" "),t("ul",[t("li",[v._v("batchsize 增加会减轻 loss 的震荡，但模型泛化能力会有下降；batchsize 下降会增加欠拟合的几率。通过几次 batchsize 的增加和减少，模型的识别率都没能提高，特别是降低 batchsize 的识别率下降更为明显。")]),v._v(" "),t("li",[v._v("当前使用的初始学习率为 0.0001，试图增加学习率后，识别率会发生骤降，而且 loss 不会收敛，目前还没找到原因。")]),v._v(" "),t("li",[v._v("通过查阅资料，发现 Adam 自适应优化器迭代过程中并不会修正 lr，尝试添加 lr 迭代，识别率下降，loss 不收敛。")])]),v._v(" "),t("p",[v._v("模型层面的微调作用并不大，因此就开始在特征提取部分做了一些尝试，Red 矩阵通道选用 WRG 加权递归图，加权递归图对特征的提取受作者提出的几个超参数的影响，于是想对这部分做了一些尝试。")]),v._v(" "),t("ul",[t("li",[v._v("修改 WRG 为无阈值递归图，无阈值递归图本质上就是距离相似矩阵，没有阈值的限制，距离相似矩阵含有更多值，可能会包含更多的特征，但经过测试，识别率降低明显，Red 矩阵值的丰富度或许会加大与 Green 和 Blue 矩阵的混淆程度。")]),v._v(" "),t("li",[v._v("以 PLAID 2017 为试点，挨着查看了一下每个电器设备的距离相似矩阵，互相之间值差别很大，因此就尝试将 WRG 的超参数修改为中位数和上四分位数，测试结果也不好")]),v._v(" "),t("li",[v._v("RG 图的核心在于发掘时间序列中的递归特性，因此在尽可能保证递归特性及不递归的基础上，增加特征信息，最后就尝试提出一种三阶段的加权递归图，选上下四分数值分别为阈值，大于上四分数取 1，小于下四分数取 0，中间值不变。效果很不好，这部分现在的想法是不应该是简单的大小比较，应该先乘一个权重系数，阈值点的选择也应该更合理。")])]),v._v(" "),t("p",[v._v("最后在模型的训练及测试流程做了一些改进，这部分取得的效果比较理想。")]),v._v(" "),t("p",[v._v("前面一直没有很好的理解 K 折交叉验证的使用方式，这周通过多方面查找资料，把这部分理解透彻。")]),v._v(" "),t("p",[v._v("通常会有两种使用方法:")]),v._v(" "),t("ol",[t("li",[v._v("先将全部数据划分为训练集和测试集，然后对训练集使用 K 折交叉验证进一步划分，分为训练集和验证集，利用验证集选出 k 个最佳参数模型，然后去测试集进行测试，最终选取最佳的识别率或者 k 个的平均识别率做泛化误差。")])]),v._v(" "),t("p",[v._v("缺点: 其一对于小规模数据集，测试集的划分减少了训练集的数据量，可能会影响模型的泛化能力；其二，说服力不够，无法保证测试集的随机性。")]),v._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[v._v("对全部的数据使用 K 折交叉验证，分为训练集和测试集，然后再从训练集中分出部分验证集。每折迭代时，选出的最好模型去预测对应测试集，依次重复 k 次上述过程，最终所有的数据都被预测过，得出一个比较完善的混淆矩阵。")])]),v._v(" "),t("p",[v._v("第二种方案虽然克服了第一种方案的缺点，但问题在于如何选取对应折的最佳模型，由于在训练集的基础上分出了验证集，使用验证集效果最好的模型去做测试。")]),v._v(" "),t("p",[t("strong",[v._v("很多文献中或者博文中提到的用验证集去调节模型的超参数，开始一直没能理解这句话，验证集是不能参与训练的，那是如何来实现超参数的调节那？这个过程其实并不是主观的参与，经过几次 epoch 或者每次 epoch，使用验证集来验证当前的训练结果，然后保存最小的 loss，实现客观的调参")])]),v._v(" "),t("p",[v._v("为了防止过拟合，在每折中加入了 early-stopping 机制，patience 取值 30。")]),v._v(" "),t("p",[v._v("本周把所有的代码都修改为第二种方案，PLAID2017 和 WHITED 数据集的识别准确率都达到了 97.5% 左右。")]),v._v(" "),t("h3",{attrs:{id:"其余工作"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#其余工作"}},[v._v("#")]),v._v(" 其余工作")]),v._v(" "),t("p",[v._v("把整体的代码系统捋了一遍，修改了几处前面遗漏的或者不注意的一些小问题。")]),v._v(" "),t("p",[v._v("WHITED 数据集最后的结果存在标签的错位，不影响识别率，但混淆矩阵中的对应会出现问题，具体还在进一步排查中。")])])}),[],!1,null,null,null);_.default=e.exports}}]);