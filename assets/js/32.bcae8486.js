(window.webpackJsonp=window.webpackJsonp||[]).push([[32],{410:function(e,t,v){"use strict";v.r(t);var a=v(51),_=Object(a.a)({},(function(){var e=this,t=e.$createElement,v=e._self._c||t;return v("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[v("h3",{attrs:{id:"文章总结"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#文章总结"}},[e._v("#")]),e._v(" 文章总结")]),e._v(" "),v("ol",[v("li",[e._v("本文主要是将深度学习的算法应用到能量(负荷)分解中，主要用到了三种算法:")])]),e._v(" "),v("ul",[v("li",[e._v("长短期记忆人工神经网络("),v("code",[e._v("LSTM")]),e._v(")")]),e._v(" "),v("li",[e._v("降噪自动解码器")]),e._v(" "),v("li",[e._v("回归各设备启动时间、结束时间和平均功率需求的网络")])]),e._v(" "),v("ol",{attrs:{start:"2"}},[v("li",[e._v("数据来源于实际采集，采集率有两种:")])]),e._v(" "),v("ul",[v("li",[e._v("1次/s")]),e._v(" "),v("li",[e._v("1次/6s")])]),e._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[e._v("数据来源包括 5 个房间，每个房间包括 5 种电器:")])]),e._v(" "),v("ul",[v("li",[e._v("kettle")]),e._v(" "),v("li",[e._v("firedge")]),e._v(" "),v("li",[e._v("washing machine")]),e._v(" "),v("li",[e._v("microwave")]),e._v(" "),v("li",[e._v("dish washer")])]),e._v(" "),v("ol",{attrs:{start:"4"}},[v("li",[e._v("论文所用数据集来自 "),v("code",[e._v("UK-DALE")])]),e._v(" "),v("li",[e._v("训练数据由两部分组成: 合成综合数据、真实数据，比例是 "),v("code",[e._v("1:1")])]),e._v(" "),v("li",[e._v("所用激活函数是 "),v("code",[e._v("linear")]),e._v(" 和 "),v("code",[e._v("tanh")]),e._v("。")]),e._v(" "),v("li",[e._v("使用 "),v("code",[e._v("NILMTK's")]),e._v(" 提供的 Electric_get_activations() 方法提取激活(???激活是负荷印记吗)")]),e._v(" "),v("li",[e._v("最后使用 "),v("code",[e._v("TP FP FN F1")]),e._v(" 等参数来评价模型的好坏，同时与之前出现的算法(CO FHMM) 进行对比，对比发现，DNN 有更好的价值。")])]),e._v(" "),v("h3",{attrs:{id:"关键字"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#关键字"}},[e._v("#")]),e._v(" 关键字")]),e._v(" "),v("p",[v("code",[e._v("Energy disaggregation; neural networks; feature learning;NILM; energy conservation; deep learning")])]),e._v(" "),v("h3",{attrs:{id:"论文学习"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#论文学习"}},[e._v("#")]),e._v(" 论文学习")]),e._v(" "),v("p",[e._v("这篇论文的感觉虽然不是综述文，但文章介绍了很多基础的深度学习知识，提出的三种方法也未给出具体实现，只给出了三种方法的基本架构，并比较了三种方法与两种基准算法的在面对已知房子和未知房子的性能比较。")]),e._v(" "),v("h4",{attrs:{id:"优点一-文章流程"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优点一-文章流程"}},[e._v("#")]),e._v(" 优点一: 文章流程")]),e._v(" "),v("p",[e._v("但文章的分析流程还是不错的，暂且记录一下:")]),e._v(" "),v("ol",[v("li",[e._v("introduce neural nets")]),e._v(" "),v("li",[e._v("convolutional neural nets")]),e._v(" "),v("li",[e._v("choice of applicances")]),e._v(" "),v("li",[e._v("extract activations")]),e._v(" "),v("li",[e._v("select windows of real aggregate data")]),e._v(" "),v("li",[e._v("synthetic aggregate data")]),e._v(" "),v("li",[e._v("standardisation")]),e._v(" "),v("li",[e._v("neural network architectures")])]),e._v(" "),v("ul",[v("li",[e._v("RNN")]),e._v(" "),v("li",[e._v("Denoising autoencoders")]),e._v(" "),v("li",[e._v("Regress start time，end time & power (这是什么算法?)")])]),e._v(" "),v("h4",{attrs:{id:"优点二-结果比较方式"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优点二-结果比较方式"}},[e._v("#")]),e._v(" 优点二: 结果比较方式")]),e._v(" "),v("p",[e._v("文章比较算法性能好坏的比较方法也很好，类似下图，将多个数据多个维度集中在一张大图上。")]),e._v(" "),[v("img",{attrs:{src:e.$withBase("/images/figure3.png"),alt:"双向rnn"}})],e._v(" "),v("h4",{attrs:{id:"优点三-文章中的某些观点"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#优点三-文章中的某些观点"}},[e._v("#")]),e._v(" 优点三: 文章中的某些观点")]),e._v(" "),v("blockquote",[v("p",[e._v("(暂且未知是否可用，先记录一下)")])]),e._v(" "),v("ol",[v("li",[e._v("We found that synthetic data acts as a regulariser: 合成数据起到了调节作用，提高网络对看不见的房屋进行归纳的能力。")]),e._v(" "),v("li",[e._v("We have done some preliminary experiments and found that neural nets appear to be able to generalise better if we independently centre each sequence:  我们已经做了一些初步实验，发现如果我们独立地集中每个序列，神经网络似乎能够更好地泛化。")])]),e._v(" "),v("h3",{attrs:{id:"知识学习"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#知识学习"}},[e._v("#")]),e._v(" 知识学习")]),e._v(" "),v("ol",[v("li",[v("p",[e._v("RNN: "),v("RouterLink",{attrs:{to:"/knowledge/rnn.html"}},[e._v("循环神经网络知识")])],1)]),e._v(" "),v("li",[v("p",[e._v("文章中提到 "),v("code",[e._v("RNN")]),e._v(" 存在梯度爆炸和消失问题，一般有三种方案解决")])])]),e._v(" "),v("ul",[v("li",[e._v("合理的初始化权重值。初始化权重，使每个神经元尽可能不要取极大值或极小值，躲避开梯度消失的区域")]),e._v(" "),v("li",[e._v("使用 "),v("code",[e._v("relu")]),e._v("(线性整流函数) 代替 "),v("code",[e._v("sigmoid")]),e._v(" 和 "),v("code",[e._v("tanh")]),e._v(" 作为激活函数")]),e._v(" "),v("li",[e._v("使用其他结构的 "),v("code",[e._v("RNN")]),e._v("，例如长短时记忆网络 "),v("code",[e._v("LTSM")]),e._v(" 和 "),v("strong",[e._v("Gated Recurrent Unit（GRU）")])])]),e._v(" "),v("ol",{attrs:{start:"3"}},[v("li",[v("RouterLink",{attrs:{to:"/knowledge/TPFPFNTNF1.html"}},[e._v("宏平均值、召回率、精准率等")])],1)]),e._v(" "),v("h3",{attrs:{id:"问题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#问题"}},[e._v("#")]),e._v(" 问题")]),e._v(" "),v("ol",[v("li",[e._v("对多状态的用电器的识别上 "),v("code",[e._v("DNN")]),e._v(" 和表现没有 "),v("code",[e._v("CO,FHMM")]),e._v(" 算法好。是否存在优化空间，或者还是有更好的算法")]),e._v(" "),v("li",[e._v("对于小功率的用电器，应该使用何种方法来进行负荷分解")]),e._v(" "),v("li",[v("code",[e._v("Select windows of real aggregate data")]),e._v(" 没完全理解这个标题")]),e._v(" "),v("li",[v("code",[e._v("We have done some preliminary experiments and found that neural nets appear to be able to generalise better if we independently centre each sequence. But there are likely to be ways to have the best of both worlds: i.e. to give the network information about the absolute power whilst also allowing the network to generalise well.")]),e._v(" 如何能实现两全其美?")]),e._v(" "),v("li",[v("code",[e._v("GRU")]),e._v(" 算法")])])],2)}),[],!1,null,null,null);t.default=_.exports}}]);