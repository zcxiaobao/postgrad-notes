---
title: 基于卷积神经网络的非侵入式负荷监测方法
lang: en-US
---
## 文章信息
+ 题目: 基于卷积神经网络的非侵入式负荷监测方法
+ 作者: 刘一铭, 李惠民, 王乐挺, Hasan RAFIQ
+ 期刊: 电测与仪表
+ 关键词: 非侵入式负荷监测；负荷分解；智能用电；深度学习；卷积神经网络；边缘计算
+ 英文关键词: non-Intrusive load monitoring, load disaggregation, smart power utilization, deep learning, convolutional neural network, edge computing


## 文章摘要
从摘要可以看出，这是一篇非常新的文章，文章结合了比较热门的边缘计算。

总结起来，大约有三大亮点:
1. 提出一种**基于物联网边缘计算场景中的 NILM 架构**，并讨论了新架构下各组成部分的任务分配。
2. 提出了基于离散度和用电行为规律分析的激活判断策略来实现负荷激活在线提取
3. 针对低频采样下的负荷特征问题，提出了一种可自动提取激活特征并识别类型的卷积神经网络架构。

## 基于物联网边缘计算场景中的 NILM 架构
边缘计算作为物联网时代，云计算存在时延高、不稳定、隐私性差等问题的补充和优化。边缘计算指的是在网络边缘结点来处理、分析数据。边缘结点指的就是在数据产生源头和云中心之间任一具有计算资源和网络资源的结点。比如手机就可以是人与云中心之间的边缘节点，网关是智能家居和云中心之间的边缘结点。

泛在电力物联网以工业物联网为蓝本，具有“整体感知、可靠传输和智能处理”的特点，与 NILM 的实时性、双向性和计算复杂性相近，体现出对 NILM 的兼容性。因此文章提出一种基于边缘计算的 NILM 系统架构。

> 这里是否存在一定的借鉴意义?


<template>
  <img :src="$withBase('/images/nilm-edge.png')" alt="叠加原理">
</template>

从上面的架构图可以看出，整个架构主要分为传感层、边缘层、云层。

其中边缘层：由具备轻量级计算能力的边缘网关群 构成，负责对传感数据进行激活检测、提取、数据预处理，输出数据上传至云层。

边缘计算模式下，数据无需传往云端，直接在距离较近的网管进行处理，增加了数据传输的稳定性，减轻了云层的负担。另外，由于数据距离边缘较近，因此数据相应的实时性会大大加强。

## 负荷激活检测与识别
### 激活检测算法
负荷状态发生改变的最直观体现是功率曲线发生类阶跃变化，样本数据的离散程度也相应增大。

文章中使用功率曲线的变化来检测负荷投切，原理大同小异，但具体实现方法存在一定区别，文章通过计算样本的局部标准差、局部平均幅值来检测潜在的投切事件。

选取合适的滑动窗口，初步筛选出负荷状态改变点。

然后使用下列的算法进行考核，记录满足条件的负荷投切点。

<template>
  <img :src="$withBase('/images/0128loadevent.png')" alt="叠加原理">
</template>

### 激活识别算法
低频采样数据易于观察负荷的启停周期及激活期间各电气量的宏观变化规律。选取低频采样的有功功率作为输入量，提取三种基础特征

<template>
  <img :src="$withBase('/images/0128loadrecognize.png')" alt="叠加原理">
</template>

文章中的激活识别算法使用 CNN 从样本中自动提取特征，结合上面三个基础特征，通过 Softmax 卷积层生成负荷类别概率。

### 神经网络结构
网络中共存在四个输入层 I1 I2 I3 I4，分别代表与处理过的激活功率向量集合、激活长度集合、中位激活功率集合、激活发生时间集合。

I1 首先输入到 ConvNet1 网络进行特征提取，之后与 I2 I3 I4 合并输入至 ConvNet2 网络进行激活分类。最终每个样本输出一个长度为 i
的 One-Hot 向量，代表 i
中激活类别的概率。

<template>
  <img :src="$withBase('/images/0128cnn-constructor.png')" alt="叠加原理">
</template>

### 特征提取卷积网络 ConvNet1
**为增加卷积网络的感受野，并便于神经网络在不同时间尺度捕捉激活特征并建立前后联系**，将一维时间数据重塑为二维矩阵，使用**二维卷积核**提取特征。

1. 为了减轻过拟合和梯度消失/爆炸，在两层卷积层之间加入 ReLU 激活层和 Batch Normalization 层。
2. 同时对前三个卷积层输出进行 Zero-Padding ，以减轻因卷积运算带来的边界效应而导致边界数据逐渐丢失
3. 输出部分，采用一个 Sigmoid 卷积层对结果进行归一化，加快了模型收敛的速度，并避免学习过程中的权重偏袒。
#### ReLU 层
ReLU 是神经网络的一个激活函数，其由于 tanh 和 sigmoid 函数。

**为什引入非线性激活函数那？**

如果不引入激活函数，在这种情况下每一层输出都是上层输入的线性函数。那么，无论神经网络有多少层，输出都是输入的线性组合，与没有隐藏层效果相当，这种情况就是最原始的感知机。当引入非线性函数作为激活函数时，不再是输入的线性组合，可以逼近任意函数，这样深层神经网络就有意义了。

**引入ReLU的原因**
1. 采用 sigmoid 等函数，激活函数计算为指数运算，计算量大；反向传播求误差梯度时，求导涉及除法，计算量相对较大，而采用 Relu 激活函数，整个过程的计算量小很多。
2. 对于深层网络，sigmoid 函数反向传播时，很容易就会出现梯度消失的情况，从而无法完成深层网络的训练。
3. ReLu 会使一部分神经元的输出为 0，形成网络相对稀疏，并且减少了参数的相互依存关系，缓解了过拟合问题的发生。






### Batch Normalization
没完全提炼出要点，留后续慢慢总结

![](https://blog.csdn.net/hjimce/article/details/50866313)

### Zero-Padding

## 激活分类卷积网络 ConvNet2

## 验证分析
验证分析与以往见到的验证分析略有不同。
### 谐波干扰分析
由于国内外的监管标准不一，同种负荷的谐波分量、电压标准等规格存在不同。因此文章为了验证模型在的泛化表现，对几件常用电器的电压电流进行 10 次高频采样，分析其谐波成分，进行识别测试。

<template>
  <img :src="$withBase('/images/0128harmonic-test.png')" alt="叠加原理">
</template>

文章通过测试发现，采集样本降重样后，文中模型也辨识出了包括谐波畸变程度较高的微波炉在内的大多数样本。说明，谐波干扰并未显著影响文中辨识算法的准确率。

### 传输数据量分析
NILM 系统对系统实时性要求非常高，因此文章还测试了边缘计算模型对数据传输量的优化。

## 总结
1. 该文章不仅是提供了事件检测和负荷识别算法，还提供了以“分布-集中”的边缘计算架构的形式部署。利用边缘网关的通信优势和分布计算能力可以解决云架构的通信稳定性，并减少云端的计算压力。
2. 文章负荷状态的类跃迁变化转变为数据点离散度的突变，通过变异系数和负荷运行规律来进行识别(**后续可用**)